# Lyra-Mistral7B-immobilier-LoRA ğŸ ğŸ’¶

## Description
Ce dÃ©pÃ´t contient le travail dâ€™adaptation **LoRA (QLoRA 4-bit)** du modÃ¨le **Mistral-7B-Instruct-v0.3**, appliquÃ© Ã  un cas dâ€™usage simple et grand public :  
**lâ€™estimation immobiliÃ¨re** Ã  partir de paramÃ¨tres structurÃ©s (surface, type, Ã©tat, zone A/B1/B2/C).

Lâ€™objectif est de montrer la capacitÃ© Ã  :
- crÃ©er un dataset synthÃ©tique calibrÃ©,
- entraÃ®ner et fusionner un modÃ¨le LoRA,
- publier le modÃ¨le complet sur Hugging Face,
- documenter le projet dans un format reproductible et exploitable.

---

## ğŸ”¹ Bilan technique
- **Base model** : `mistralai/Mistral-7B-Instruct-v0.3`  
- **Technique** : QLoRA (4-bit, bitsandbytes)  
- **GPU** : A100 (Colab Pro)  
- **Epochs** : 3  
- **Modules LoRA** : q_proj, k_proj, v_proj, o_proj, down_proj  
- **Fusion & export** : `merge_and_unload()` â†’ modÃ¨le complet pushÃ© sur Hugging Face Hub  
- **Test** : comparaison *base vs LoRA* â†’ le LoRA produit des rÃ©ponses concises et cadrÃ©es, sans hallucination de villes, respectant le format attendu.  

---

## ğŸ”¹ Valeur professionnelle
- **Vitrine MLOps lÃ©gÃ¨re** : pipeline complet de fine-tuning â†’ fusion â†’ publication â†’ documentation.  
- **Cas dâ€™usage accessible** : montre comment un modÃ¨le 7B peut Ãªtre adaptÃ© Ã  un secteur concret (immobilier), avec intÃ©gration possible dans un workflow (n8n / Make / API).  

---

## ğŸ”— Liens
- ğŸ“¦ ModÃ¨le Hugging Face : [Lyra-Mistral7B-immobilier-LoRA](https://huggingface.co/jeromex1/Lyra-Mistral7B-immobilier-LoRA)  
- ğŸ“˜ Autres projets Lyra (40+ repos IA & STEM) : [github.com/Jerome-openclassroom](https://github.com/Jerome-openclassroom/)  

---

## ğŸ”¹ Exemple dâ€™utilisation

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

model_id = "jeromex1/Lyra-Mistral7B-immobilier-LoRA"

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    device_map="auto",
    torch_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16
)

system_prompt = (
    "Tu es un expert en estimation immobiliÃ¨re. "
    "RÃ©ponds en franÃ§ais, de maniÃ¨re concise, en 1 Ã  2 phrases maximum. "
    "Donne une estimation chiffrÃ©e (fourchette en euros) et un bref commentaire. "
    "Les localisations sont classÃ©es par zone : A, B1, B2 ou C. "
    "NE MENTIONNE PAS de villes ou rÃ©gions, uniquement la zone donnÃ©e."
)

user_prompt = "Surface : 96 mÂ²\nType : maison\nÃ‰tat : bon\nZone : B1"
full_prompt = f"{system_prompt}\n\n{user_prompt}\n\nRÃ©ponse :"

inputs = tokenizer(full_prompt, return_tensors="pt").to(model.device)
outputs = model.generate(**inputs, max_new_tokens=80)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```

---

## ğŸ”¹ Exemples de rÃ©sultats
| Prompt (input) | RÃ©ponse (LoRA) |
|----------------|----------------|
| Surface : 96 mÂ²<br>Type : maison<br>Ã‰tat : bon<br>Zone : B1 | Valeur estimÃ©e entre 300 000 â‚¬ et 400 000 â‚¬. Bien situÃ© dans une zone B1, cette maison de 96 mÂ² est en trÃ¨s bon Ã©tat. |
| Surface : 55 mÂ²<br>Type : appartement<br>Ã‰tat : Ã  rÃ©nover<br>Zone : C | Estimation : 100 000 â€“ 120 000 â‚¬<br>Commentaire : Appartement Ã  rÃ©nover dans une zone C, l'estimation est comprise entre 100 000 et 120 000 â‚¬. |
| Surface : 120 mÂ²<br>Type : maison<br>Ã‰tat : excellent<br>Zone : A | Valeur estimÃ©e entre 500 000 â‚¬ et 600 000 â‚¬. Situation privilÃ©giÃ©e, grande surface et Ã©tat excellent. |

---
